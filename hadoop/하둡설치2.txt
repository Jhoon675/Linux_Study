rm -rf .ssh 
ssh-keygen -t rsa

ls -al .ssh
우리가 가지고 있는 pub키를 상대방에 cp요청을해라

ssh-copy-id -i /home/hadoop/.ssh/id_rsa.pub hadoop@192.168.56.100
이것을 설정한 뒤에 로그인시 비밀번호를 안물어보면 성공! (서버간의 신뢰를 만들어주는것)

namenode 포멧
hadoop namenode -format

방화벽 상태확인
sudo firewall-cmd --list-all
sudo firewall-cmd --permanent --zone=public --add-port=50070/tcp
sudo firewall-cmd --permanent --zone=public --add-port=50075/tcp
sudo firewall-cmd --permanent --zone=public --add-port=8042/tcp
sudo firewall-cmd --permanent --zone=public --add-port=8088/tcp

sudo systemctl restart firewalld 을 해야 적용


hdfs 관리
hdfs dfs --help 도움말


eclipse (java)
maven -> maven project -> next -> fillter: hadoop -> hadoop-archetype
-> next
group id: 임의 설정 ( com.bit)
artifact id: myhadoop
version: 0.0.1 까지만
package: myhadoop만 남기고 지워서 길이를 줄여준다.

pom.xml : 기본 세팅
dependecy version setting

<artifactId>maven-compiler-plugin</artifactId>
        <version>3.3</version>
        <configuration>
        	<source>1.8</source>
        	<target>1.8</target>
        </configuration>

project 우클릭 maven run
goals: clean install

빨간 10줄은 log기록
BUILD SUCCESS 나오면 성공
우클릭 show in > system Explorer : 실제 파일 디렉토리 위치

자바 임포트 꿀팁 ctrl + shi +o
웹에서 winscp 검색 -> download 
winscp 실행 
192.168.56.100 -> hostname hadoop 으로 설정 후 로그인
-> myhadoop-0.0.1.jar 넣기

xsheel 
hadoop jar
hadoop jar myhadoop-0.0.1.jar myhadoop.HdfsWriteMessage

hadoop jar myhadoop-0.0.1.jar myhadoop.HdfsWriteMessage /example/test.txt Hello

hdfs dfs -cat /example/test.txt //확인

도메인 window 속이기
C:\Windows\System32\drivers\etc

내용읽기
hdfs dfs -cat /example/myhadoop/test.txt

mapreduce
maping class
reduce class
이 2가지를 묶어줄 driver class 3개가 필요하다

hadoop jar hadoop-mapreduce-examples-2.9.2.jar wordcount /example/README.txt /output
hdfs dfs -cat /output/part-r-00000

자바에서 만든 mapreduce 파일 컴파일 확인.
hadoop jar myhadoop-0.0.1.jar myhadoop.WordCount /example/README.txt output/word_count.txt




하둡 정보 보기 코끼리 사이트
http://192.168.56.100:8088/cluster

